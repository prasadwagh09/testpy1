{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebc1823",
   "metadata": {},
   "source": [
    "Steps to run notebook:\n",
    "1. Create a conda env with python3.8 (Empty conda env)\n",
    "```\n",
    "conda create --name snowml python=3.8\n",
    "```\n",
    "2. Activate conda env\n",
    "```\n",
    "conda activate snowml\n",
    "```\n",
    "3. Install conda pkg\n",
    "```\n",
    "conda install snowflake-ml-python \n",
    "# or local build if there are changes in SnowML lib you need: bazel build //snowflake/ml:wheel\n",
    "# then do pip install {built pkg}\n",
    "```\n",
    "4. Install jupyter notebook\n",
    "```\n",
    "conda install jupyter\n",
    "```\n",
    "5. Start notebook\n",
    "```\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae3429",
   "metadata": {},
   "source": [
    "## Basic Feature Store Usage Example\n",
    "This notebook demonstrates feature store usage for static features.\n",
    "The reference example by Databricks is here: https://docs.databricks.com/en/_extras/notebooks/source/machine-learning/feature-store-with-uc-basic-example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd0549",
   "metadata": {},
   "source": [
    "## Setup UI and Auto Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale cell width with the browser window to accommodate .show() commands for wider tables.\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0f7e5",
   "metadata": {},
   "source": [
    "#### [Optional 1] Import from local code repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "776268d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Simplify reading from the local repository\n",
    "cwd=os.getcwd()\n",
    "REPO_PREFIX=\"snowflake/ml\"\n",
    "LOCAL_REPO_PATH=cwd[:cwd.find(REPO_PREFIX)].rstrip('/')\n",
    "\n",
    "if LOCAL_REPO_PATH not in sys.path:\n",
    "    print(f\"Adding {LOCAL_REPO_PATH} to system path\")\n",
    "    sys.path.append(LOCAL_REPO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65029121",
   "metadata": {},
   "source": [
    "#### [Optional 2] Import from installed snowflake-ml-python wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db7fa435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/tmp/snowml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "714787e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.ml.feature_store.feature_view import FeatureView\n",
    "from snowflake.ml.feature_store.entity import Entity\n",
    "from snowflake.ml.feature_store.feature_store import FeatureStore, CreationMode\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "005f6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ba9be",
   "metadata": {},
   "source": [
    "## Prepare demo data\n",
    "\n",
    "We will use wine quality dataset to demonstrate feature store usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60407c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\"file://winequality-red.csv\", session.get_session_stage())\n",
    "\n",
    "SOURCE_DB = session.get_current_database()\n",
    "SOURCE_SCHEMA = session.get_current_schema()\n",
    "\n",
    "from snowflake.snowpark.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "input_schema = StructType(\n",
    "    [\n",
    "        StructField(\"fixed_acidity\", FloatType()), \n",
    "        StructField(\"volatile_acidity\", FloatType()), \n",
    "        StructField(\"citric_acid\", FloatType()), \n",
    "        StructField(\"residual_sugar\", FloatType()), \n",
    "        StructField(\"chlorides\", FloatType()), \n",
    "        StructField(\"free_sulfur_dioxide\", IntegerType()),\n",
    "        StructField(\"total_sulfur_dioxide\", IntegerType()), \n",
    "        StructField(\"density\", FloatType()), \n",
    "        StructField(\"pH\", FloatType()), \n",
    "        StructField(\"sulphates\", FloatType()),\n",
    "        StructField(\"alcohol\", FloatType()), \n",
    "        StructField(\"quality\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "df = session.read.options({\"field_delimiter\": \";\", \"skip_header\": 1}).schema(input_schema).csv(f\"{session.get_session_stage()}/winequality-red.csv\")\n",
    "df.write.mode(\"overwrite\").save_as_table(\"wine_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fda65",
   "metadata": {},
   "source": [
    "## Generate new synthetic data [Optional]\n",
    "Run the cell below to generate new synthetic data for the wine dataset if needed.\n",
    "NOTE: the synthetic data will be randomized based on the original data's statistics, so it may affect training quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.feature_store._internal.synthetic_data_generator import (\n",
    "    SyntheticDataGenerator,\n",
    ")\n",
    "session2 = Session.builder.configs(SnowflakeLoginOptions()).create()\n",
    "generator = SyntheticDataGenerator(session2, SOURCE_DB, SOURCE_SCHEMA, \"wine_data\")\n",
    "generator.trigger(batch_size=10, num_batches=30, freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece7a2b",
   "metadata": {},
   "source": [
    "## Create FeatureStore Client\n",
    "\n",
    "Let's first create a feature store client.\n",
    "\n",
    "We can pass in an existing database name, or a new database will be created upon the feature store initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe850ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped 10 rows to table wine_data.\n"
     ]
    }
   ],
   "source": [
    "DEMO_DB = \"FS_DEMO_DB\"\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {DEMO_DB}\").collect()  # start from scratch\n",
    "session.sql(f\"CREATE DATABASE IF NOT EXISTS {DEMO_DB}\").collect()\n",
    "session.sql(f\"CREATE OR REPLACE WAREHOUSE PUBLIC WITH WAREHOUSE_SIZE='XSMALL'\").collect()\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=DEMO_DB, \n",
    "    name=\"AWESOME_FS\", \n",
    "    default_warehouse=\"PUBLIC\",\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b7ad1",
   "metadata": {},
   "source": [
    "## Create and register a new Entity\n",
    "\n",
    "We will create an Entity called *wine* and register it with the feature store.\n",
    "\n",
    "You can retrieve the active Entities in the feature store with list_entities() API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = Entity(name=\"wine\", join_keys=[\"wine_id\"])\n",
    "fs.register_entity(entity)\n",
    "fs.list_entities().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a529d7",
   "metadata": {},
   "source": [
    "## Load source data and do some simple feature engineering\n",
    "\n",
    "Then we will load from the source table and conduct some simple feature engineerings.\n",
    "\n",
    "Here we are just doing two simple data manipulation (but more complex ones are carried out the same way):\n",
    "1. Assign a wine_id column to the source\n",
    "2. Derive a new column by multipying two existing feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6037ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = session.table(f\"{SOURCE_DB}.{SOURCE_SCHEMA}.wine_data\")\n",
    "source_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addIdColumn(df, id_column_name):\n",
    "    # Add id column to dataframe\n",
    "    columns = df.columns\n",
    "    new_df = df.withColumn(id_column_name, F.monotonically_increasing_id())\n",
    "    return new_df[[id_column_name] + columns]\n",
    "\n",
    "def generate_new_feature(df):\n",
    "    # Derive a new feature column\n",
    "    return df.withColumn(\"my_new_feature\", df[\"FIXED_ACIDITY\"] * df[\"CITRIC_ACID\"])\n",
    "\n",
    "df = addIdColumn(source_df, \"wine_id\")\n",
    "feature_df = generate_new_feature(df)\n",
    "feature_df = feature_df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'FIXED_ACIDITY',\n",
    "        'VOLATILE_ACIDITY',\n",
    "        'CITRIC_ACID',\n",
    "        'RESIDUAL_SUGAR',\n",
    "        'CHLORIDES',\n",
    "        'FREE_SULFUR_DIOXIDE',\n",
    "        'TOTAL_SULFUR_DIOXIDE',\n",
    "        'DENSITY',\n",
    "        'PH',\n",
    "        'my_new_feature',\n",
    "    ]\n",
    ")\n",
    "feature_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4be7da",
   "metadata": {},
   "source": [
    "## Create a new FeatureView and materialize the feature pipeline\n",
    "\n",
    "Once the FeatureView construction is done, we can materialize the FeatureView to the Snowflake backend and incremental maintenance will start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = FeatureView(name=\"wine_features\", entities=[entity], feature_df=feature_df, desc=\"wine features\")\n",
    "fs.register_feature_view(feature_view=fv, version=\"v1\", refresh_freq=\"1 minute\", block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the FeatureView content\n",
    "fs.read_feature_view(fv).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fc02a",
   "metadata": {},
   "source": [
    "## Explore additional features\n",
    "\n",
    "Now I have my FeatureView created with a collection of features, but what if I want to explore additional features on top?\n",
    "\n",
    "Since a materialized FeatureView is immutable (due to singe DDL for the backend dynamic table), we will need to create a new FeatureView for the additional features and then merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feature_df = df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'SULPHATES',\n",
    "        'ALCOHOL',\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_fv = FeatureView(name=\"extra_wine_features\", entities=[entity], feature_df=extra_feature_df, desc=\"extra wine features\")\n",
    "fs.register_feature_view(feature_view=new_fv, version=\"v1\", refresh_freq=\"1 minute\", block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily retrieve all FeatureViews for a given Entity.\n",
    "fs.list_feature_views(entity_name=\"wine\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cec24",
   "metadata": {},
   "source": [
    "## Create new feature view with combined feature results [Optional]\n",
    "\n",
    "Now we have two FeatureViews ready, we can choose to create a new one by merging the two (it's just like a join and we provide a handy function for that). The new FeatureView won't incur the cost of feature pipelines but only the table join cost.\n",
    "\n",
    "Obviously we can also just work with two separate FeatureViews (most of our APIs support multiple FeatureViews), the capability of merging is just to make the features better organized and easier to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fv = fs.merge_features(features=[fv, new_fv], name=\"full_wine_features\")\n",
    "fs.register_feature_view(feature_view=full_fv, version=\"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1a7dc",
   "metadata": {},
   "source": [
    "## Generate Training Data\n",
    "\n",
    "After our feature pipelines are fully setup, we can start using them to generate training data and later do model prediction.\n",
    "\n",
    "Generate training data is easy since materialized FeatureViews already carry most of the metadata like join keys, timestamp for point-in-time lookup, etc. We just need to provide the spine data (it's called spine because we are essentially enriching the data by joining features with it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "spine_df = session.table(f\"{SOURCE_DB}.{SOURCE_SCHEMA}.wine_data\")\n",
    "spine_df = addIdColumn(source_df, \"wine_id\")\n",
    "spine_df = spine_df.select(\"wine_id\", \"quality\")\n",
    "spine_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(f\"DROP TABLE IF EXISTS FS_DEMO_DB.AWESOME_FS.wine_training_data_table\").collect()\n",
    "training_data = fs.generate_dataset(\n",
    "    spine_df=spine_df, \n",
    "    features=[full_fv], \n",
    "    materialized_table=\"wine_training_data_table\", \n",
    "    spine_timestamp_col=None, \n",
    "    spine_label_cols=[\"quality\"],\n",
    "    save_mode=\"merge\",\n",
    ")\n",
    "\n",
    "training_pd = training_data.df.to_pandas()\n",
    "training_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7543",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "Now let's training a simple random forest model and evaluate the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29747582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = training_pd.drop(\"QUALITY\", axis=1)\n",
    "y = training_pd[\"QUALITY\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127da5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    ## fit and log model \n",
    "    rf = RandomForestRegressor(max_depth=3, n_estimators=20, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"MSE: {mse}, Accuracy: {round(100*(1-np.mean(np.abs((y_test - y_pred) / np.abs(y_test)))))}\")\n",
    "    return rf\n",
    "        \n",
    "rf = train_model(X_train, X_test, y_train, y_test)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81639",
   "metadata": {},
   "source": [
    "## Log model with Model Registry\n",
    "\n",
    "We can log the model along with its training dataset metadata with model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import model_registry\n",
    "from tests.integ.snowflake.ml.test_utils import (\n",
    "    test_env_utils,\n",
    ")\n",
    "\n",
    "registry = model_registry.ModelRegistry(session=session, database_name=\"my_cool_registry\", create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = registry.log_model(\n",
    "    model_name=\"my_random_forest_regressor\",\n",
    "    model_version=\"v1\",\n",
    "    model=rf,\n",
    "    tags={\"author\": \"my_rf_with_training_data\"},\n",
    "    conda_dependencies=[\n",
    "        test_env_utils.get_latest_package_versions_in_server(session, \"snowflake-snowpark-python\")\n",
    "    ],\n",
    "    dataset=training_data,\n",
    "    options={\"embed_local_ml_library\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf2743",
   "metadata": {},
   "source": [
    "## Restore model and predict with latest features\n",
    "\n",
    "We retrieve the training dataset from registry then construct dataframe of latest feature values. Then we restore the model from registry. At last, we can predict with latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_training_data = registry.get_dataset(\n",
    "    model_name=\"my_random_forest_regressor\", \n",
    "    model_version=\"v1\",\n",
    ")\n",
    "\n",
    "test_pdf = training_pd.sample(3, random_state=996)[['WINE_ID']]\n",
    "test_df = session.create_dataframe(test_pdf)\n",
    "\n",
    "latest_features = fs.retrieve_feature_values(test_df, registered_training_data.load_features())\n",
    "latest_features_pdf = latest_features.to_pandas()\n",
    "print(latest_features_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = model_registry.ModelReference(registry=registry, model_name=\"my_random_forest_regressor\", model_version=\"v1\")\n",
    "restored_model = model_ref.load_model()  # type: ignore[attr-defined]\n",
    "restored_prediction = restored_model.predict(latest_features_pdf)\n",
    "\n",
    "print(restored_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
