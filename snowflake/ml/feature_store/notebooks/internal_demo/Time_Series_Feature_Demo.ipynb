{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ce01b3",
   "metadata": {},
   "source": [
    "Steps to run notebook:\n",
    "1. Create a conda env with python3.8 (Empty conda env)\n",
    "```\n",
    "conda create --name snowml python=3.8\n",
    "```\n",
    "2. Activate conda env\n",
    "```\n",
    "conda activate snowml\n",
    "```\n",
    "3. Install conda pkg\n",
    "```\n",
    "conda install snowflake-ml-python \n",
    "# or local build if there are changes in SnowML lib you need: bazel build //snowflake/ml:wheel\n",
    "# then do pip install {built pkg}\n",
    "```\n",
    "4. Install jupyter notebook\n",
    "```\n",
    "conda install jupyter\n",
    "```\n",
    "5. Start notebook\n",
    "```\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160eb3e",
   "metadata": {},
   "source": [
    "## Feature Store Example with Time Series Features\n",
    "This notebook demonstrates advanced feature store usage with time series features. \n",
    "It will compute features from NY taxi trip data and demonstrate connections between training and prediction.\n",
    "The reference example by Databricks is here: https://docs.databricks.com/en/_extras/notebooks/source/machine-learning/feature-store-with-uc-taxi-example.html#feature-store/feature-store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f4de1",
   "metadata": {},
   "source": [
    "## Setup UI and Auto Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da1a922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Scale cell width with the browser window to accommodate .show() commands for wider tables.\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3d0e0",
   "metadata": {},
   "source": [
    "#### [Optional 1] Import from local code repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11935b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Simplify reading from the local repository\n",
    "cwd=os.getcwd()\n",
    "REPO_PREFIX=\"snowflake/ml\"\n",
    "LOCAL_REPO_PATH=cwd[:cwd.find(REPO_PREFIX)].rstrip('/')\n",
    "\n",
    "if LOCAL_REPO_PATH not in sys.path:\n",
    "    print(f\"Adding {LOCAL_REPO_PATH} to system path\")\n",
    "    sys.path.append(LOCAL_REPO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd3a7d",
   "metadata": {},
   "source": [
    "#### [Optional 2] Import from installed snowflake-ml-python wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "conda_env = os.environ['CONDA_DEFAULT_ENV']\n",
    "import sys\n",
    "sys.path.append(f'/opt/homebrew/anaconda3/envs/{conda_env}/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5ac3a",
   "metadata": {},
   "source": [
    "## Prepare demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f39a3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F, types as T\n",
    "from snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark.types import DateType, TimeType, _NumericType, TimestampType\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e665bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75bfcfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"TRIP_DISTANCE\"  |\"FARE_AMOUNT\"  |\"PASSENGER_COUNT\"  |\"PULOCATIONID\"  |\"DOLOCATIONID\"  |\"PICKUP_TS\"          |\"DROPOFF_TS\"         |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "|3.2              |14.0           |1                  |48              |262             |2016-01-01 00:12:22  |2016-01-01 00:29:14  |\n",
      "|1.0              |9.5            |2                  |162             |48              |2016-01-01 00:41:31  |2016-01-01 00:55:10  |\n",
      "|0.9              |6.0            |1                  |246             |90              |2016-01-01 00:53:37  |2016-01-01 00:59:57  |\n",
      "|0.8              |5.0            |1                  |170             |162             |2016-01-01 00:13:28  |2016-01-01 00:18:07  |\n",
      "|1.8              |11.0           |1                  |161             |140             |2016-01-01 00:33:04  |2016-01-01 00:47:14  |\n",
      "|2.3              |11.0           |1                  |141             |137             |2016-01-01 00:49:47  |2016-01-01 01:04:44  |\n",
      "|13.8             |43.0           |1                  |100             |53              |2016-01-01 00:41:58  |2016-01-01 01:22:06  |\n",
      "|3.46             |20.0           |5                  |48              |79              |2016-01-01 00:25:28  |2016-01-01 00:55:46  |\n",
      "|0.83             |5.5            |4                  |79              |107             |2016-01-01 00:56:57  |2016-01-01 01:02:24  |\n",
      "|0.87             |7.0            |1                  |164             |164             |2016-01-01 00:10:08  |2016-01-01 00:23:05  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_df = session.table(\"SNOWML_FEATURE_STORE_TEST_DB.TEST_DATASET.yellow_tripdata_2016_01\")\n",
    "\n",
    "source_df = source_df.select(\n",
    "    [\n",
    "        \"TRIP_DISTANCE\", \n",
    "        \"FARE_AMOUNT\",\n",
    "        \"PASSENGER_COUNT\",\n",
    "        \"PULOCATIONID\",\n",
    "        \"DOLOCATIONID\",\n",
    "        F.cast(source_df.TPEP_PICKUP_DATETIME / 1000000, TimestampType()).alias(\"PICKUP_TS\"),\n",
    "        F.cast(source_df.TPEP_DROPOFF_DATETIME / 1000000, TimestampType()).alias(\"DROPOFF_TS\"),\n",
    "    ]).filter(\"DROPOFF_TS >= '2016-01-01 00:00:00' AND DROPOFF_TS < '2016-01-03 00:00:00'\")\n",
    "source_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52162799",
   "metadata": {},
   "source": [
    "## Create FeatureStore Client\n",
    "\n",
    "Let's first create a feature store client.\n",
    "\n",
    "We can pass in an existing database name, or a new database will be created upon the feature store initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c37a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_DB = \"FS_TIME_SERIES_EXAMPLE\"\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {DEMO_DB}\").collect()  # start from scratch\n",
    "session.sql(f\"CREATE DATABASE IF NOT EXISTS {DEMO_DB}\").collect()\n",
    "session.sql(f\"CREATE OR REPLACE WAREHOUSE PUBLIC WITH WAREHOUSE_SIZE='XSMALL'\").collect()\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=DEMO_DB, \n",
    "    name=\"AWESOME_FS\", \n",
    "    default_warehouse=\"PUBLIC\",\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d052074",
   "metadata": {},
   "source": [
    "## Create and register new Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70609920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>JOIN_KEYS</th>\n",
       "      <th>DESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRIP_DROPOFF</td>\n",
       "      <td>DOLOCATIONID</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRIP_PICKUP</td>\n",
       "      <td>PULOCATIONID</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NAME     JOIN_KEYS DESC\n",
       "0  TRIP_DROPOFF  DOLOCATIONID     \n",
       "1   TRIP_PICKUP  PULOCATIONID     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_pickup = Entity(name=\"trip_pickup\", join_keys=[\"PULOCATIONID\"])\n",
    "trip_dropoff = Entity(name=\"trip_dropoff\", join_keys=[\"DOLOCATIONID\"])\n",
    "fs.register_entity(trip_pickup)\n",
    "fs.register_entity(trip_dropoff)\n",
    "fs.list_entities().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c4393",
   "metadata": {},
   "source": [
    "## Define feature pipeline\n",
    "We will compute a few time series features in the pipeline here.\n",
    "Before we have *__value based range between__* in SQL, we will use a work around to mimic the calculation (NOTE: the work around won't be very accurate on computing the time series value due to missing gap filling functionality, but it should be enough for a demo purpose)\n",
    "\n",
    "We will define two feature groups:\n",
    "1. pickup features\n",
    "    - Mean fare amount over the past 2 and 5 hours\n",
    "2. dropoff features\n",
    "    - Count of trips over the past 2 and 5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71729be3",
   "metadata": {},
   "source": [
    "### This is a UDF computing time window end\n",
    "We will later turn these into built in functions for feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "995b4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(\n",
    "    name=\"vec_window_end\",\n",
    "    is_permanent=True,\n",
    "    stage_location=session.get_session_stage(),\n",
    "    packages=[\"numpy\", \"pandas\", \"pytimeparse\"],\n",
    "    replace=True,\n",
    "    session=session,\n",
    "    immutable=True,\n",
    ")\n",
    "def vec_window_end_compute(\n",
    "    x: T.PandasSeries[datetime.datetime],\n",
    "    interval: T.PandasSeries[str],\n",
    ") -> T.PandasSeries[datetime.datetime]:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pytimeparse.timeparse import timeparse\n",
    "\n",
    "    time_slice = timeparse(interval[0])\n",
    "    if time_slice is None:\n",
    "        raise ValueError(f\"Cannot parse interval {interval[0]}\")\n",
    "    time_slot = (x - np.datetime64('1970-01-01T00:00:00')) // np.timedelta64(1, 's') // time_slice * time_slice + time_slice\n",
    "    return pd.to_datetime(time_slot, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73742b89",
   "metadata": {},
   "source": [
    "### Define feature pipeline logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d0c4339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"PULOCATIONID\"  |\"TS\"                 |\"MEAN_FARE_2_HR\"    |\"MEAN_FARE_5_HR\"    |\n",
      "----------------------------------------------------------------------------------\n",
      "|98              |2016-01-01 04:45:00  |26.0                |26.0                |\n",
      "|98              |2016-01-01 14:00:00  |19.75               |19.75               |\n",
      "|98              |2016-01-02 22:30:00  |156.5               |156.5               |\n",
      "|225             |2016-01-01 00:30:00  |9.6                 |9.6                 |\n",
      "|225             |2016-01-01 00:45:00  |11.833333333333334  |11.833333333333334  |\n",
      "|225             |2016-01-01 01:00:00  |15.045454545454545  |15.045454545454545  |\n",
      "|225             |2016-01-01 01:15:00  |13.928571428571429  |13.928571428571429  |\n",
      "|225             |2016-01-01 01:30:00  |12.717948717948717  |12.717948717948717  |\n",
      "|225             |2016-01-01 01:45:00  |13.169811320754716  |13.169811320754716  |\n",
      "|225             |2016-01-01 02:00:00  |12.607142857142858  |12.607142857142858  |\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "|\"DOLOCATIONID\"  |\"TS\"                 |\"COUNT_TRIP_2_HR\"  |\"COUNT_TRIP_5_HR\"  |\n",
      "--------------------------------------------------------------------------------\n",
      "|227             |2016-01-01 00:30:00  |2                  |2                  |\n",
      "|227             |2016-01-01 00:45:00  |5                  |5                  |\n",
      "|227             |2016-01-01 01:00:00  |12                 |12                 |\n",
      "|227             |2016-01-01 01:15:00  |16                 |16                 |\n",
      "|227             |2016-01-01 01:30:00  |21                 |21                 |\n",
      "|227             |2016-01-01 01:45:00  |25                 |25                 |\n",
      "|227             |2016-01-01 02:00:00  |33                 |33                 |\n",
      "|227             |2016-01-01 02:15:00  |43                 |43                 |\n",
      "|227             |2016-01-01 02:30:00  |48                 |50                 |\n",
      "|227             |2016-01-01 02:45:00  |53                 |58                 |\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Window\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "# NOTE: these time window calculations are approximates and are not handling time gaps\n",
    "\n",
    "def pre_aggregate_fn(df, ts_col, group_by_cols):\n",
    "    df = df.with_column(\"WINDOW_END\", F.call_udf(\"vec_window_end\", F.col(ts_col), \"15m\"))\n",
    "    df = df.group_by(group_by_cols + [\"WINDOW_END\"]).agg(\n",
    "            F.sum(\"FARE_AMOUNT\").alias(\"FARE_SUM_1_hr\"),\n",
    "            F.count(\"*\").alias(\"TRIP_COUNT_1_hr\")\n",
    "         )\n",
    "    return df\n",
    "\n",
    "def pickup_features_fn(df):\n",
    "    df = pre_aggregate_fn(df, \"PICKUP_TS\", [\"PULOCATIONID\"])\n",
    "    \n",
    "    window1 = Window.partition_by(\"PULOCATIONID\").order_by(col(\"WINDOW_END\").desc()).rows_between(Window.CURRENT_ROW, 7)\n",
    "    window2 = Window.partition_by(\"PULOCATIONID\").order_by(col(\"WINDOW_END\").desc()).rows_between(Window.CURRENT_ROW, 19)\n",
    "\n",
    "    df = df.with_columns(\n",
    "        [\n",
    "            \"SUM_FARE_2_hr\",\n",
    "            \"COUNT_TRIP_2hr\",\n",
    "            \"SUM_FARE_5_hr\",\n",
    "            \"COUNT_TRIP_5hr\",\n",
    "        ],\n",
    "        [\n",
    "            F.sum(\"FARE_SUM_1_hr\").over(window1),\n",
    "            F.sum(\"TRIP_COUNT_1_hr\").over(window1),\n",
    "            F.sum(\"FARE_SUM_1_hr\").over(window2),\n",
    "            F.sum(\"TRIP_COUNT_1_hr\").over(window2),\n",
    "        ]\n",
    "    ).select(\n",
    "        [\n",
    "            col(\"PULOCATIONID\"),\n",
    "            col(\"WINDOW_END\").alias(\"TS\"),\n",
    "            (col(\"SUM_FARE_2_hr\") / col(\"COUNT_TRIP_2hr\")).alias(\"MEAN_FARE_2_hr\"),\n",
    "            (col(\"SUM_FARE_5_hr\") / col(\"COUNT_TRIP_5hr\")).alias(\"MEAN_FARE_5_hr\"),\n",
    "        ]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def dropoff_features_fn(df):\n",
    "    df = pre_aggregate_fn(df, \"DROPOFF_TS\", [\"DOLOCATIONID\"])\n",
    "    window1 = Window.partition_by(\"DOLOCATIONID\").order_by(col(\"WINDOW_END\").desc()).rows_between(Window.CURRENT_ROW, 7)\n",
    "    window2 = Window.partition_by(\"DOLOCATIONID\").order_by(col(\"WINDOW_END\").desc()).rows_between(Window.CURRENT_ROW, 19)\n",
    "\n",
    "    df = df.select(\n",
    "        [\n",
    "            col(\"DOLOCATIONID\"),\n",
    "            col(\"WINDOW_END\").alias(\"TS\"),\n",
    "            F.sum(\"TRIP_COUNT_1_hr\").over(window1).alias(\"COUNT_TRIP_2_hr\"),\n",
    "            F.sum(\"TRIP_COUNT_1_hr\").over(window2).alias(\"COUNT_TRIP_5_hr\"),\n",
    "        ]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "pickup_df = pickup_features_fn(source_df)\n",
    "pickup_df.show()\n",
    "\n",
    "dropoff_df = dropoff_features_fn(source_df)\n",
    "dropoff_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46fa4f",
   "metadata": {},
   "source": [
    "## Create FeatureViews and materialize\n",
    "\n",
    "Once the FeatureView construction is done, we can materialize the FeatureView to the Snowflake backend and incremental maintenance will start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0cd2075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tbao/Desktop/Snowflake/snowml/snowflake/ml/feature_store/feature_store.py:334: UserWarning: Your pipeline won't be incrementally refreshed due to: \"Query contains the function 'VEC_WINDOW_END', but change tracking is not supported on queries with non-IMMUTABLE user-defined functions.\". It will likely incurr higher cost.\n",
      "  self._create_dynamic_table(\n"
     ]
    }
   ],
   "source": [
    "pickup_fv = FeatureView(\n",
    "    name=\"trip_pickup_features\", \n",
    "    entities=[trip_pickup], \n",
    "    feature_df=pickup_df, \n",
    "    timestamp_col=\"ts\",\n",
    "    refresh_freq=\"1 minute\",\n",
    ").attach_feature_desc({\"MEAN_FARE_2_HR\": \"avg fare over past 2hr\"})\n",
    "pickup_fv = fs.register_feature_view(feature_view=pickup_fv, version=\"v1\", block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8960b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_fv = FeatureView(\n",
    "    name=\"trip_dropoff_features\", \n",
    "    entities=[trip_dropoff], \n",
    "    feature_df=dropoff_df, \n",
    "    timestamp_col=\"ts\",\n",
    "    refresh_freq=\"1 minute\",\n",
    ").attach_feature_desc({\"COUNT_TRIP_2_HR\": \"trip count over past 2hr\"})\n",
    "dropoff_fv = fs.register_feature_view(feature_view=dropoff_fv, version=\"v1\", block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02009c81",
   "metadata": {},
   "source": [
    "## Explore FeatureViews\n",
    "We can easily discover what are the materialized FeatureViews and the corresponding features with *__fs.list_feature_views()__*. \n",
    "\n",
    "We can also apply filters based on Entity name or FeatureView names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc93de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------\n",
      "|\"NAME\"                 |\"VERSION\"  |\"ENTITIES\"                  |\"FEATURE_DESC\"                                    |\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "|TRIP_DROPOFF_FEATURES  |V1         |[                           |{                                                 |\n",
      "|                       |           |  {                         |  \"COUNT_TRIP_2_HR\": \"trip count over past 2hr\",  |\n",
      "|                       |           |    \"desc\": \"\",             |  \"COUNT_TRIP_5_HR\": \"\"                           |\n",
      "|                       |           |    \"join_keys\": [          |}                                                 |\n",
      "|                       |           |      \"DOLOCATIONID\"        |                                                  |\n",
      "|                       |           |    ],                      |                                                  |\n",
      "|                       |           |    \"name\": \"TRIP_DROPOFF\"  |                                                  |\n",
      "|                       |           |  }                         |                                                  |\n",
      "|                       |           |]                           |                                                  |\n",
      "|TRIP_PICKUP_FEATURES   |V1         |[                           |{                                                 |\n",
      "|                       |           |  {                         |  \"MEAN_FARE_2_HR\": \"\",                           |\n",
      "|                       |           |    \"desc\": \"\",             |  \"MEAN_FARE_5_HR\": \"\"                            |\n",
      "|                       |           |    \"join_keys\": [          |}                                                 |\n",
      "|                       |           |      \"PULOCATIONID\"        |                                                  |\n",
      "|                       |           |    ],                      |                                                  |\n",
      "|                       |           |    \"name\": \"TRIP_PICKUP\"   |                                                  |\n",
      "|                       |           |  }                         |                                                  |\n",
      "|                       |           |]                           |                                                  |\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs.list_feature_views().select([\"NAME\", \"VERSION\", \"ENTITIES\", \"FEATURE_DESC\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302cf23",
   "metadata": {},
   "source": [
    "## Generate training data and train a model\n",
    "The training data generation will lookup __point-in-time correct__ feature values and join with the spine dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4e3376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"DOLOCATIONID\"  |\"PICKUP_TS\"          |\"PULOCATIONID\"  |\"FARE_AMOUNT\"  |\"MEAN_FARE_2_HR\"    |\"MEAN_FARE_5_HR\"    |\"COUNT_TRIP_2_HR\"  |\"COUNT_TRIP_5_HR\"  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|262             |2016-01-01 00:12:22  |48              |14.0           |NULL                |NULL                |NULL               |NULL               |\n",
      "|48              |2016-01-01 00:41:31  |162             |9.5            |11.451428571428572  |11.451428571428572  |137                |137                |\n",
      "|90              |2016-01-01 00:53:37  |246             |6.0            |13.765232974910393  |13.765232974910393  |214                |214                |\n",
      "|162             |2016-01-01 00:13:28  |170             |5.0            |NULL                |NULL                |NULL               |NULL               |\n",
      "|140             |2016-01-01 00:33:04  |161             |11.0           |13.203869047619047  |13.203869047619047  |83                 |83                 |\n",
      "|137             |2016-01-01 00:49:47  |141             |11.0           |10.352534562211982  |10.352534562211982  |244                |244                |\n",
      "|53              |2016-01-01 00:41:58  |100             |43.0           |15.816091954022989  |15.816091954022989  |NULL               |NULL               |\n",
      "|79              |2016-01-01 00:25:28  |48              |20.0           |15.685714285714285  |15.685714285714285  |43                 |43                 |\n",
      "|79              |2016-01-01 00:25:28  |48              |20.0           |15.685714285714285  |15.685714285714285  |43                 |43                 |\n",
      "|79              |2016-01-01 00:25:28  |48              |20.0           |15.685714285714285  |15.685714285714285  |43                 |43                 |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT * FROM FS_TIME_SERIES_EXAMPLE.AWESOME_FS.yellow_tripdata_2016_01_training_data_2023_12_12_14_10_32'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spine_df = source_df.select([\"PULOCATIONID\", \"DOLOCATIONID\", \"PICKUP_TS\", \"FARE_AMOUNT\"])\n",
    "training_data = fs.generate_dataset(\n",
    "    spine_df=spine_df,\n",
    "    features=[pickup_fv, dropoff_fv],\n",
    "    materialized_table=\"yellow_tripdata_2016_01_training_data\",\n",
    "    spine_timestamp_col=\"PICKUP_TS\",\n",
    "    spine_label_cols = [\"FARE_AMOUNT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bced5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLOCATIONID</th>\n",
       "      <th>PULOCATIONID</th>\n",
       "      <th>MEAN_FARE_2_HR</th>\n",
       "      <th>MEAN_FARE_5_HR</th>\n",
       "      <th>COUNT_TRIP_2_HR</th>\n",
       "      <th>COUNT_TRIP_5_HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359595</th>\n",
       "      <td>90</td>\n",
       "      <td>249</td>\n",
       "      <td>8.806985</td>\n",
       "      <td>9.258179</td>\n",
       "      <td>404.0</td>\n",
       "      <td>995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360562</th>\n",
       "      <td>170</td>\n",
       "      <td>79</td>\n",
       "      <td>10.242111</td>\n",
       "      <td>10.517555</td>\n",
       "      <td>821.0</td>\n",
       "      <td>2251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681540</th>\n",
       "      <td>50</td>\n",
       "      <td>107</td>\n",
       "      <td>9.416096</td>\n",
       "      <td>9.226157</td>\n",
       "      <td>394.0</td>\n",
       "      <td>956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951079</th>\n",
       "      <td>48</td>\n",
       "      <td>151</td>\n",
       "      <td>10.308511</td>\n",
       "      <td>10.278940</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477164</th>\n",
       "      <td>79</td>\n",
       "      <td>249</td>\n",
       "      <td>9.562016</td>\n",
       "      <td>9.554124</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>2827.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DOLOCATIONID  PULOCATIONID  MEAN_FARE_2_HR  MEAN_FARE_5_HR  \\\n",
       "359595            90           249        8.806985        9.258179   \n",
       "360562           170            79       10.242111       10.517555   \n",
       "681540            50           107        9.416096        9.226157   \n",
       "951079            48           151       10.308511       10.278940   \n",
       "477164            79           249        9.562016        9.554124   \n",
       "\n",
       "        COUNT_TRIP_2_HR  COUNT_TRIP_5_HR  \n",
       "359595            404.0            995.0  \n",
       "360562            821.0           2251.0  \n",
       "681540            394.0            956.0  \n",
       "951079           1289.0           3380.0  \n",
       "477164           1124.0           2827.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "training_pd = training_data.df.to_pandas()\n",
    "X = training_pd.drop([\"FARE_AMOUNT\", \"PICKUP_TS\"], axis=1)\n",
    "y = training_pd[\"FARE_AMOUNT\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f0e6902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1498254012058 %\n",
      "Mean squared error: 91.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "estimator = make_pipeline(imp, LinearRegression())\n",
    "\n",
    "reg = estimator.fit(X, y)\n",
    "r2_score = reg.score(X_test, y_test)\n",
    "print(r2_score * 100,'%')\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0142c25c",
   "metadata": {},
   "source": [
    "## Log model with Model Registry\n",
    "We can log the model along with its training dataset metadata with model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c57a81e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The database \"my_cool_registry\" already exists. Skipping creation.\n",
      "WARNING:absl:The schema \"my_cool_registry\"._SYSTEM_MODEL_REGISTRY_SCHEMA already exists. Skipping creation.\n"
     ]
    }
   ],
   "source": [
    "from snowflake.ml.registry import model_registry, artifact\n",
    "import time\n",
    "\n",
    "registry = model_registry.ModelRegistry(session=session, database_name=\"my_cool_registry\", create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4caab287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:ModelRegistry.log_artifact() is in private preview since 1.0.10. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"MY_DATASET\"\n",
    "DATASET_VERSION = f\"V1_{time.time()}\"\n",
    "\n",
    "my_dataset = registry.log_artifact(\n",
    "    artifact=training_data,\n",
    "    name=DATASET_NAME,\n",
    "    version=DATASET_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a935926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/feature_store_demo/lib/python3.8/site-packages/snowflake/ml/model/model_signature.py:55: UserWarning: The sample input has 959457 rows, thus a truncation happened before inferring signature. This might cause inaccurate signature inference. If that happens, consider specifying signature manually.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"MY_MODEL\"\n",
    "model_version = f\"V1_{time.time()}\"\n",
    "\n",
    "model_ref = registry.log_model(\n",
    "    model_name=model_name,\n",
    "    model_version=model_version,\n",
    "    model=estimator,\n",
    "    artifacts=[my_dataset],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0581d",
   "metadata": {},
   "source": [
    "## Restore model and predict with latest features\n",
    "We retrieve the training dataset from registry then construct dataframe of latest feature values. Then we restore the model from registry. At last, we can predict with latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a18a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark:FeatureStore.retrieve_feature_values() is in private preview since 1.0.8. Do not use it in production. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.71003863 13.95909809 13.95909809 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      " 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268 11.70994268\n",
      "  9.7267722  10.61725586 10.61725586 12.77915638 12.77915638 12.77915638\n",
      " 15.89874567 13.24272348 13.24272348 13.24272348 13.24272348]\n"
     ]
    }
   ],
   "source": [
    "pred_df = training_data.df.sample(0.01).select(\n",
    "    ['PULOCATIONID', 'DOLOCATIONID', 'PICKUP_TS'])\n",
    "\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    spine_df=pred_df, \n",
    "    features=training_data.load_features(), \n",
    "    spine_timestamp_col='PICKUP_TS'\n",
    ").drop(['PICKUP_TS']).to_pandas()\n",
    "\n",
    "pred = estimator.predict(enriched_df)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd545ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = model_registry.ModelReference(\n",
    "    registry=registry, \n",
    "    model_name=model_name, \n",
    "    model_version=model_version,\n",
    ").load_model()\n",
    "\n",
    "pred = model_ref.predict(enriched_df)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad5af0",
   "metadata": {},
   "source": [
    "## DO NOT READ\n",
    "Below is a simple test for the window_end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ba589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import functions as F, types as T\n",
    "import datetime\n",
    "\n",
    "session = Session.builder.configs(SnowflakeLoginOptions()).create()\n",
    "\n",
    "udf_name = \"window_end\"\n",
    "    \n",
    "@F.pandas_udf(\n",
    "    name=udf_name,\n",
    "    replace=True,\n",
    "    packages=[\"numpy\", \"pandas\", \"pytimeparse\"],\n",
    "    session=session,\n",
    ")\n",
    "def vec_window_end_compute(\n",
    "    x: T.PandasSeries[datetime.datetime],\n",
    "    interval: T.PandasSeries[str],\n",
    ") -> T.PandasSeries[datetime.datetime]:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from pytimeparse.timeparse import timeparse\n",
    "\n",
    "    time_slice = timeparse(interval[0])\n",
    "    if time_slice is None:\n",
    "        raise ValueError(f\"Cannot parse interval {interval[0]}\")\n",
    "    time_slot = (x - np.datetime64('1970-01-01T00:00:00')) // np.timedelta64(1, 's') // time_slice * time_slice + time_slice\n",
    "    return pd.to_datetime(time_slot, unit='s')\n",
    "\n",
    "df = session.create_dataframe(\n",
    "    [\n",
    "        '2023-01-31 01:02:03.004',\n",
    "        '2023-01-31 01:14:59.999',\n",
    "        '2023-01-31 01:15:00.000',\n",
    "        '2023-01-31 01:15:00.004',\n",
    "        '2023-01-31 01:17:10.007',\n",
    "    ], \n",
    "    schema=['a']\n",
    ")\n",
    "df = df.select([F.to_timestamp(\"a\").alias(\"ts\")])\n",
    "\n",
    "df = df.select([\"TS\", F.call_udf(udf_name, F.col(\"TS\"), \"15m\").alias(\"window_end\")])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"select window_end(ts, '15m') from foobar\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:feature_store_demo]",
   "language": "python",
   "name": "conda-env-feature_store_demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
