{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb54abc",
   "metadata": {},
   "source": [
    "Version: 0.1.0\n",
    "\n",
    "Updated date: 10/10/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae3429",
   "metadata": {},
   "source": [
    "## Basic Feature Demo\n",
    "\n",
    "This notebook demonstrates feature store with simple features. It includes an end-2-end ML experiment cycle: feature creation, training and inference. It also demonstrate the interoperation between Feature Store and Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714787e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16e6a8",
   "metadata": {},
   "source": [
    "## Setup Snowflake connection\n",
    "For detailed session connection config, please follow this [tutorial](https://medium.com/snowflake/snowflakeloginoptions-an-easier-way-to-connect-using-python-2f0e726da936).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ba9be",
   "metadata": {},
   "source": [
    "## Prepare test data\n",
    "\n",
    "We will use wine quality dataset for this demo. Download the public dataset from kaggle if you dont have it already: https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009. Replace `TEST_CSV_FILE_PATH` with your local file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60407c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV_FILE_PATH = 'winequality-red.csv'\n",
    "session.file.put(\n",
    "    f\"file://{TEST_CSV_FILE_PATH}\",session.get_session_stage())\n",
    "\n",
    "SOURCE_DB = session.get_current_database()\n",
    "SOURCE_SCHEMA = session.get_current_schema()\n",
    "\n",
    "from snowflake.snowpark.types import (\n",
    "    StructType, \n",
    "    StructField, \n",
    "    IntegerType, \n",
    "    FloatType\n",
    ")\n",
    "input_schema = StructType(\n",
    "    [\n",
    "        StructField(\"fixed_acidity\", FloatType()), \n",
    "        StructField(\"volatile_acidity\", FloatType()), \n",
    "        StructField(\"citric_acid\", FloatType()), \n",
    "        StructField(\"residual_sugar\", FloatType()), \n",
    "        StructField(\"chlorides\", FloatType()), \n",
    "        StructField(\"free_sulfur_dioxide\", IntegerType()),\n",
    "        StructField(\"total_sulfur_dioxide\", IntegerType()), \n",
    "        StructField(\"density\", FloatType()), \n",
    "        StructField(\"pH\", FloatType()), \n",
    "        StructField(\"sulphates\", FloatType()),\n",
    "        StructField(\"alcohol\", FloatType()), \n",
    "        StructField(\"quality\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "df = session.read.options({\"field_delimiter\": \";\", \"skip_header\": 1}) \\\n",
    "    .schema(input_schema) \\\n",
    "    .csv(f\"{session.get_session_stage()}/winequality-red.csv\")\n",
    "df.write.mode(\"overwrite\").save_as_table(\"wine_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece7a2b",
   "metadata": {},
   "source": [
    "## Create FeatureStore Client\n",
    "\n",
    "Let's first create a feature store client.\n",
    "\n",
    "We can pass in an existing database name, or a new database will be created upon the feature store initialization. Replace `DEMO_DB` and `DEMO_SCHEMA` with your database and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe850ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_DB = \"FS_DEMO_DB\"\n",
    "DEMO_SCHEMA = \"AWESOME_FS\"\n",
    "\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {DEMO_DB}\").collect()\n",
    "session.sql(f\"CREATE DATABASE IF NOT EXISTS {DEMO_DB}\").collect()\n",
    "session.sql(f\"\"\"CREATE OR REPLACE WAREHOUSE PUBLIC WITH \n",
    "                WAREHOUSE_SIZE='XSMALL'\n",
    "            \"\"\").collect()\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=DEMO_DB, \n",
    "    name=DEMO_SCHEMA, \n",
    "    default_warehouse=\"PUBLIC\",\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b7ad1",
   "metadata": {},
   "source": [
    "## Create and register a new Entity\n",
    "\n",
    "We will create an Entity called *wine* and register it with the feature store.\n",
    "\n",
    "You can retrieve the active Entities in the feature store with list_entities() API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = Entity(name=\"wine\", join_keys=[\"wine_id\"])\n",
    "fs.register_entity(entity)\n",
    "fs.list_entities().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a529d7",
   "metadata": {},
   "source": [
    "## Load source data and do some simple feature engineering\n",
    "\n",
    "Then we will load from the source table and conduct some simple feature engineerings.\n",
    "\n",
    "Here we are just doing two simple data manipulation (but more complex ones are carried out the same way):\n",
    "1. Assign a wine_id column to the source\n",
    "2. Derive a new column by multipying two existing feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6037ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = session.table(f\"{SOURCE_DB}.{SOURCE_SCHEMA}.wine_data\")\n",
    "source_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addIdColumn(df, id_column_name):\n",
    "    # Add id column to dataframe\n",
    "    columns = df.columns\n",
    "    new_df = df.withColumn(id_column_name, F.monotonically_increasing_id())\n",
    "    return new_df[[id_column_name] + columns]\n",
    "\n",
    "def generate_new_feature(df):\n",
    "    # Derive a new feature column\n",
    "    return df.withColumn(\n",
    "        \"my_new_feature\", df[\"FIXED_ACIDITY\"] * df[\"CITRIC_ACID\"])\n",
    "\n",
    "df = addIdColumn(source_df, \"wine_id\")\n",
    "feature_df = generate_new_feature(df)\n",
    "feature_df = feature_df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'FIXED_ACIDITY',\n",
    "        'VOLATILE_ACIDITY',\n",
    "        'CITRIC_ACID',\n",
    "        'RESIDUAL_SUGAR',\n",
    "        'CHLORIDES',\n",
    "        'FREE_SULFUR_DIOXIDE',\n",
    "        'TOTAL_SULFUR_DIOXIDE',\n",
    "        'DENSITY',\n",
    "        'PH',\n",
    "        'my_new_feature',\n",
    "    ]\n",
    ")\n",
    "feature_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4be7da",
   "metadata": {},
   "source": [
    "## Create a new FeatureView and materialize the feature pipeline\n",
    "\n",
    "Once the FeatureView construction is done, we can materialize the FeatureView to the Snowflake backend and incremental maintenance will start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b631144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Due to a known issue on backend pipeline creation, \n",
    "# if the source data is created right before the \n",
    "# feature pipeline, there might be a chance for \n",
    "# dataloss, so sleep for 60s for now.\n",
    "# This issue will be fixed soon in upcoming patch.\n",
    "\n",
    "import time\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = FeatureView(\n",
    "    name=\"wine_features\", \n",
    "    entities=[entity], \n",
    "    feature_df=feature_df, \n",
    "    desc=\"wine features\"\n",
    ")\n",
    "fs.register_feature_view(\n",
    "    feature_view=fv, \n",
    "    version=\"v1\", \n",
    "    refresh_freq=\"1 minute\", \n",
    "    block=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the FeatureView content\n",
    "fs.read_feature_view(fv).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fc02a",
   "metadata": {},
   "source": [
    "## Explore additional features\n",
    "\n",
    "Now I have my FeatureView created with a collection of features, but what if I want to explore additional features on top?\n",
    "\n",
    "Since a materialized FeatureView is immutable (due to singe DDL for the backend dynamic table), we will need to create a new FeatureView for the additional features and then merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feature_df = df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'SULPHATES',\n",
    "        'ALCOHOL',\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_fv = FeatureView(\n",
    "    name=\"extra_wine_features\", \n",
    "    entities=[entity], \n",
    "    feature_df=extra_feature_df, \n",
    "    desc=\"extra wine features\"\n",
    ")\n",
    "fs.register_feature_view(\n",
    "    feature_view=new_fv, \n",
    "    version=\"v1\", \n",
    "    refresh_freq=\"1 minute\", \n",
    "    block=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily retrieve all FeatureViews for a given Entity.\n",
    "fs.list_feature_views(entity_name=\"wine\").select([\"NAME\", \"ENTITIES\", \"FEATURE_DESC\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cec24",
   "metadata": {},
   "source": [
    "## Create new feature view with combined feature results [Optional]\n",
    "\n",
    "Now we have two FeatureViews ready, we can choose to create a new one by merging the two (it's just like a join and we provide a handy function for that). The new FeatureView won't incur the cost of feature pipelines but only the table join cost.\n",
    "\n",
    "Obviously we can also just work with two separate FeatureViews (most of our APIs support multiple FeatureViews), the capability of merging is just to make the features better organized and easier to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fv = fs.merge_features(\n",
    "    features=[fv, new_fv], name=\"full_wine_features\")\n",
    "fs.register_feature_view(feature_view=full_fv, version=\"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1a7dc",
   "metadata": {},
   "source": [
    "## Generate Training Data\n",
    "\n",
    "After our feature pipelines are fully setup, we can start using them to generate training data and later do model prediction.\n",
    "\n",
    "Generate training data is easy since materialized FeatureViews already carry most of the metadata like join keys, timestamp for point-in-time lookup, etc. We just need to provide the spine data (it's called spine because we are essentially enriching the data by joining features with it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "spine_df = session.table(f\"{SOURCE_DB}.{SOURCE_SCHEMA}.wine_data\")\n",
    "spine_df = addIdColumn(source_df, \"wine_id\")\n",
    "spine_df = spine_df.select(\"wine_id\", \"quality\")\n",
    "spine_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_full_path = f\"{DEMO_DB}.{DEMO_SCHEMA}.wine_training_data_table\"\n",
    "session.sql(f\"DROP TABLE IF EXISTS {training_dataset_full_path}\").collect()\n",
    "training_data = fs.generate_dataset(\n",
    "    spine_df=spine_df, \n",
    "    features=[full_fv], \n",
    "    materialized_table=\"wine_training_data_table\", \n",
    "    spine_timestamp_col=None, \n",
    "    spine_label_cols=[\"quality\"],\n",
    "    save_mode=\"merge\",\n",
    "    exclude_columns=['wine_id']\n",
    ")\n",
    "\n",
    "training_data.df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7543",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "Now let's training a simple random forest model with snowflake.ml library, and evaluate the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29747582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "training_pd = training_data.df.to_pandas()\n",
    "X = training_pd.drop(\"QUALITY\", axis=1)\n",
    "y = training_pd[\"QUALITY\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127da5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestRegressor(\n",
    "        max_depth=3, n_estimators=20, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    accuracy = round(100*(1-np.mean(\n",
    "        np.abs((y_test - y_pred) / np.abs(y_test)))))\n",
    "    print(f\"MSE: {mse}, Accuracy: {accuracy}\")\n",
    "    return rf\n",
    "        \n",
    "rf = train_model(X_train, X_test, y_train, y_test)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81639",
   "metadata": {},
   "source": [
    "## Log model with Model Registry\n",
    "\n",
    "We can log the model along with its training dataset metadata with model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import model_registry, artifact\n",
    "import time\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=\"my_cool_registry\", \n",
    "    create_if_not_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5642606",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_ref = registry.log_artifact(\n",
    "    artifact_type=artifact.ArtifactType.DATASET,\n",
    "    artifact_name=\"my_cool_dataset\",\n",
    "    artifact_spec=training_data.to_json(),\n",
    "    artifact_version=\"v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"my_random_forest_regressor{time.time()}\"\n",
    "\n",
    "model_ref = registry.log_model(\n",
    "    model_name=model_name,\n",
    "    model_version=\"v2\",\n",
    "    model=rf,\n",
    "    tags={\"author\": \"my_rf_with_training_data\"},\n",
    "    artifacts=[artifact_ref],\n",
    "    options={\"embed_local_ml_library\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf2743",
   "metadata": {},
   "source": [
    "## Restore model and predict with latest features\n",
    "\n",
    "We retrieve the training dataset from registry then construct dataframe of latest feature values. Then we restore the model from registry. At last, we can predict with latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.dataset.dataset import Dataset\n",
    "\n",
    "registered_artifact = registry.get_artifact(artifact_ref.id)\n",
    "\n",
    "registered_dataset = Dataset.from_json(registered_artifact.spec, session)\n",
    "\n",
    "# test_pdf = training_pd.sample(3, random_state=996)[['WINE_ID']]\n",
    "test_df = spine_df.limit(3).select(\"WINE_ID\")\n",
    "# test_df = session.create_dataframe(test_pdf)\n",
    "\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    test_df, registered_dataset.load_features())\n",
    "enriched_df = enriched_df.drop('wine_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = model_registry.ModelReference(\n",
    "    registry=registry, \n",
    "    model_name=model_name, \n",
    "    model_version=\"v2\"\n",
    ")\n",
    "restored_model = model_ref.load_model()\n",
    "restored_prediction = restored_model.predict(enriched_df.to_pandas())\n",
    "\n",
    "print(restored_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
