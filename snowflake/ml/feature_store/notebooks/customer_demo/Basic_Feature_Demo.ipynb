{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb54abc",
   "metadata": {},
   "source": [
    "- snowflake-ml-python version: 1.1.0\n",
    "- Feature Store PrPr Version: 0.3.1\n",
    "- Updated date: 12/11/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c09b2",
   "metadata": {},
   "source": [
    "## Before getting started\n",
    "\n",
    "### Watch out object name case sensitivity\n",
    "The Model Registry and Feature Store are not consistent with each other in the way they case names for databases, schemas, and other SQL objects. (Keep in mind that the objects in both APIs are Snowflake objects on the back end.) The model registry preserves the case of names for these objects, while the feature store converts names to uppercase unless you enclose them in double quotes. The way the feature store handles names is consistent with Snowflakeâ€™s identifier requirements. We are working to make this more consistent. In the meantime, we suggest using uppercase names in both APIs to ensure correct interoperation between the feature store and the model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeae3429",
   "metadata": {},
   "source": [
    "## Basic Feature Demo\n",
    "\n",
    "This notebook demonstrates feature store with simple features. It includes an end-2-end ML experiment cycle: feature creation, training and inference. It also demonstrate the interoperation between Feature Store and Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714787e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16e6a8",
   "metadata": {},
   "source": [
    "## Setup Snowflake connection and database\n",
    "For detailed session connection config, please follow this [tutorial](https://medium.com/snowflake/snowflakeloginoptions-an-easier-way-to-connect-using-python-2f0e726da936).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(SnowflakeLoginOptions()).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e1503",
   "metadata": {},
   "source": [
    "Below cell creates temporary database, schema and warehouse for this notebook. All temporary resources will be deleted at the end of this notebook. You can rename with your own name if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9622928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database name where test data and feature store lives.\n",
    "FS_DEMO_DB = f\"FEATURE_STORE_BASIC_FEATURE_NOTEBOOK_DEMO\"\n",
    "# schema where test data lives.\n",
    "TEST_DATASET_SCHEMA = 'TEST_DATASET'\n",
    "# feature store name.\n",
    "FS_DEMO_SCHEMA = \"AWESOME_FS_BASIC_FEATURES\"\n",
    "# Model registry database name.\n",
    "MR_DEMO_DB = f\"FEATURE_STORE_BASIC_FEATURE_NOTEBOOK_MR_DEMO\"\n",
    "# warehouse name used in this notebook.\n",
    "FS_DEMO_WH = \"FEATURE_STORE_BASIC_FEATURE_NOTEBOOK_DEMO\"\n",
    "\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {FS_DEMO_DB}\").collect()\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {MR_DEMO_DB}\").collect()\n",
    "session.sql(f\"CREATE DATABASE IF NOT EXISTS {FS_DEMO_DB}\").collect()\n",
    "session.sql(f\"\"\"\n",
    "    CREATE SCHEMA IF NOT EXISTS \n",
    "    {FS_DEMO_DB}.{TEST_DATASET_SCHEMA}\"\"\").collect()\n",
    "session.sql(f\"CREATE WAREHOUSE IF NOT EXISTS {FS_DEMO_WH}\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece7a2b",
   "metadata": {},
   "source": [
    "## Create FeatureStore Client\n",
    "\n",
    "Let's first create a feature store client.\n",
    "\n",
    "We can pass in an existing database name, or a new database will be created upon the feature store initialization. Replace `DEMO_DB` and `DEMO_SCHEMA` with your database and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe850ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=FS_DEMO_DB, \n",
    "    name=FS_DEMO_SCHEMA, \n",
    "    default_warehouse=FS_DEMO_WH,\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ba9be",
   "metadata": {},
   "source": [
    "## Prepare test data\n",
    "\n",
    "We will use wine quality dataset for this demo. Download the public dataset from kaggle if you dont have it already: https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009. Replace `TEST_CSV_FILE_PATH` with your local file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60407c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV_FILE_PATH = 'winequality-red.csv'\n",
    "session.file.put(\n",
    "    f\"file://{TEST_CSV_FILE_PATH}\",session.get_session_stage())\n",
    "\n",
    "from snowflake.snowpark.types import (\n",
    "    StructType, \n",
    "    StructField, \n",
    "    IntegerType, \n",
    "    FloatType\n",
    ")\n",
    "input_schema = StructType(\n",
    "    [\n",
    "        StructField(\"fixed_acidity\", FloatType()), \n",
    "        StructField(\"volatile_acidity\", FloatType()), \n",
    "        StructField(\"citric_acid\", FloatType()), \n",
    "        StructField(\"residual_sugar\", FloatType()), \n",
    "        StructField(\"chlorides\", FloatType()), \n",
    "        StructField(\"free_sulfur_dioxide\", IntegerType()),\n",
    "        StructField(\"total_sulfur_dioxide\", IntegerType()), \n",
    "        StructField(\"density\", FloatType()), \n",
    "        StructField(\"pH\", FloatType()), \n",
    "        StructField(\"sulphates\", FloatType()),\n",
    "        StructField(\"alcohol\", FloatType()), \n",
    "        StructField(\"quality\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "df = session.read.options({\"field_delimiter\": \";\", \"skip_header\": 1}) \\\n",
    "    .schema(input_schema) \\\n",
    "    .csv(f\"{session.get_session_stage()}/winequality-red.csv\")\n",
    "full_table_name = f\"{FS_DEMO_DB}.{TEST_DATASET_SCHEMA}.WINE_DATA\"\n",
    "df.write.mode(\"overwrite\").save_as_table(full_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b7ad1",
   "metadata": {},
   "source": [
    "## Create and register a new Entity\n",
    "\n",
    "We will create an Entity called *wine* and register it with the feature store.\n",
    "\n",
    "You can retrieve the active Entities in the feature store with list_entities() API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = Entity(name=\"WINE\", join_keys=[\"WINE_ID\"])\n",
    "fs.register_entity(entity)\n",
    "fs.list_entities().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a529d7",
   "metadata": {},
   "source": [
    "## Load source data and do some simple feature engineering\n",
    "\n",
    "Then we will load from the source table and conduct some simple feature engineerings.\n",
    "\n",
    "Here we are just doing two simple data manipulation (but more complex ones are carried out the same way):\n",
    "1. Assign a WINE_ID column to the source\n",
    "2. Derive a new column by multipying two existing feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6037ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = session.table(full_table_name)\n",
    "source_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addIdColumn(df, id_column_name):\n",
    "    # Add id column to dataframe\n",
    "    columns = df.columns\n",
    "    new_df = df.withColumn(id_column_name, F.monotonically_increasing_id())\n",
    "    return new_df[[id_column_name] + columns]\n",
    "\n",
    "def generate_new_feature(df):\n",
    "    # Derive a new feature column\n",
    "    return df.withColumn(\n",
    "        \"MY_NEW_FEATURE\", df[\"FIXED_ACIDITY\"] * df[\"CITRIC_ACID\"])\n",
    "\n",
    "df = addIdColumn(source_df, \"WINE_ID\")\n",
    "feature_df = generate_new_feature(df)\n",
    "feature_df = feature_df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'FIXED_ACIDITY',\n",
    "        'VOLATILE_ACIDITY',\n",
    "        'CITRIC_ACID',\n",
    "        'RESIDUAL_SUGAR',\n",
    "        'CHLORIDES',\n",
    "        'FREE_SULFUR_DIOXIDE',\n",
    "        'TOTAL_SULFUR_DIOXIDE',\n",
    "        'DENSITY',\n",
    "        'PH',\n",
    "        'MY_NEW_FEATURE',\n",
    "    ]\n",
    ")\n",
    "feature_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4be7da",
   "metadata": {},
   "source": [
    "## Create a new FeatureView and materialize the feature pipeline\n",
    "\n",
    "Once the FeatureView construction is done, we can materialize the FeatureView to the Snowflake backend and incremental maintenance will start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b631144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Due to a known issue on backend pipeline creation, \n",
    "# if the source data is created right before the \n",
    "# feature pipeline, there might be a chance for \n",
    "# dataloss, so sleep for 60s for now.\n",
    "# This issue will be fixed soon in upcoming patch.\n",
    "\n",
    "import time\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = FeatureView(\n",
    "    name=\"WINE_FEATURES\", \n",
    "    entities=[entity], \n",
    "    feature_df=feature_df, \n",
    "    refresh_freq=\"1 minute\", \n",
    "    desc=\"wine features\"\n",
    ")\n",
    "fv = fs.register_feature_view(\n",
    "    feature_view=fv, \n",
    "    version=\"V1\", \n",
    "    block=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the FeatureView content\n",
    "fs.read_feature_view(fv).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fc02a",
   "metadata": {},
   "source": [
    "## Explore additional features\n",
    "\n",
    "Now I have my FeatureView created with a collection of features, but what if I want to explore additional features on top?\n",
    "\n",
    "Since a materialized FeatureView is immutable (due to singe DDL for the backend dynamic table), we will need to create a new FeatureView for the additional features and then merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feature_df = df.select(\n",
    "    [\n",
    "        'WINE_ID',\n",
    "        'SULPHATES',\n",
    "        'ALCOHOL',\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_fv = FeatureView(\n",
    "    name=\"EXTRA_WINE_FEATURES\", \n",
    "    entities=[entity], \n",
    "    feature_df=extra_feature_df, \n",
    "    refresh_freq=\"1 minute\", \n",
    "    desc=\"extra wine features\"\n",
    ")\n",
    "new_fv = fs.register_feature_view(\n",
    "    feature_view=new_fv, \n",
    "    version=\"V1\", \n",
    "    block=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily retrieve all FeatureViews for a given Entity.\n",
    "fs.list_feature_views(entity_name=\"WINE\"). \\\n",
    "    select([\"NAME\", \"ENTITIES\", \"FEATURE_DESC\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cec24",
   "metadata": {},
   "source": [
    "## Create new feature view with combined feature results [Optional]\n",
    "\n",
    "Now we have two FeatureViews ready, we can choose to create a new one by merging the two (it's just like a join and we provide a handy function for that). The new FeatureView won't incur the cost of feature pipelines but only the table join cost.\n",
    "\n",
    "Obviously we can also just work with two separate FeatureViews (most of our APIs support multiple FeatureViews), the capability of merging is just to make the features better organized and easier to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fv = fs.merge_features(\n",
    "    features=[fv, new_fv], name=\"FULL_WINE_FEATURES\")\n",
    "full_fv = fs.register_feature_view(feature_view=full_fv, version=\"V1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1a7dc",
   "metadata": {},
   "source": [
    "## Generate Training Data\n",
    "\n",
    "After our feature pipelines are fully setup, we can start using them to generate training data and later do model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "spine_df = session.table(f\"{FS_DEMO_DB}.{TEST_DATASET_SCHEMA}.WINE_DATA\")\n",
    "spine_df = addIdColumn(source_df, \"WINE_ID\")\n",
    "spine_df = spine_df.select(\"WINE_ID\", \"QUALITY\")\n",
    "spine_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad126af",
   "metadata": {},
   "source": [
    "Generate training data is easy since materialized FeatureViews already carry most of the metadata like join keys, timestamp for point-in-time lookup, etc. We just need to provide the spine data (it's called spine because we are essentially enriching the data by joining features with it). We can also generate dataset with a subset of features in the feature view by `slice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_full_path = \\\n",
    "    f\"{FS_DEMO_DB}.{FS_DEMO_SCHEMA}.WINE_TRAINING_DATA_TABLE\"\n",
    "session.sql(f\"DROP TABLE IF EXISTS {training_dataset_full_path}\") \\\n",
    "    .collect()\n",
    "training_data = fs.generate_dataset(\n",
    "    spine_df=spine_df, \n",
    "    features=[\n",
    "        full_fv.slice([\n",
    "            \"FIXED_ACIDITY\", \n",
    "            \"VOLATILE_ACIDITY\", \n",
    "            \"CITRIC_ACID\"\n",
    "        ])\n",
    "    ], \n",
    "    materialized_table=\"WINE_TRAINING_DATA_TABLE\", \n",
    "    spine_timestamp_col=None, \n",
    "    spine_label_cols=[\"QUALITY\"],\n",
    "    save_mode=\"merge\",\n",
    "    exclude_columns=['WINE_ID']\n",
    ")\n",
    "\n",
    "training_data.df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca7543",
   "metadata": {},
   "source": [
    "## Train model with Snowpark ML\n",
    "\n",
    "Now let's training a simple random forest model, and evaluate the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.ensemble import RandomForestRegressor\n",
    "from snowflake.ml.modeling import metrics as snowml_metrics\n",
    "from snowflake.snowpark.functions import abs as sp_abs, mean, col\n",
    "\n",
    "def train_model_using_snowpark_ml(training_data):\n",
    "    train, test = training_data.df.random_split([0.8, 0.2], seed=42)\n",
    "    feature_columns = [col for col in training_data.df.columns if col != \"QUALITY\"]\n",
    "    label_column = \"QUALITY\"\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        input_cols=feature_columns, label_cols=[label_column], \n",
    "        max_depth=3, n_estimators=20, random_state=42\n",
    "    )\n",
    "\n",
    "    rf.fit(train)\n",
    "    predictions = rf.predict(test)\n",
    "\n",
    "    mse = snowml_metrics.mean_squared_error(\n",
    "        df=predictions, \n",
    "        y_true_col_names=label_column, \n",
    "        y_pred_col_names=\"OUTPUT_\" + label_column)\n",
    "\n",
    "    accuracy = 100 - snowml_metrics.mean_absolute_percentage_error(\n",
    "        df=predictions,\n",
    "        y_true_col_names=label_column,\n",
    "        y_pred_col_names=\"OUTPUT_\" + label_column\n",
    "    )\n",
    "\n",
    "    print(f\"MSE: {mse}, Accuracy: {accuracy}\")\n",
    "    return rf\n",
    "\n",
    "rf = train_model_using_snowpark_ml(training_data)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8031f",
   "metadata": {},
   "source": [
    "## [Predict Optional 1] With local model\n",
    "Now let's predict with the model and the feature values retrieved from feature store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spine_df.limit(3).select(\"WINE_ID\")\n",
    "\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    test_df, training_data.load_features())\n",
    "enriched_df = enriched_df.drop('WINE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(enriched_df.to_pandas())\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81639",
   "metadata": {},
   "source": [
    "## [Predict Option 2] Using Model Registry\n",
    "\n",
    "### Step 1 : Log the model along with its training dataset metadata into Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import model_registry\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MR_DEMO_DB, \n",
    "    create_if_not_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb2531",
   "metadata": {},
   "source": [
    "Register the dataset into model registry with `log_artifact`. Artifact is a generalized concept of ML pipeline outputs that are needed for subsequent execution. Refer to https://docs.snowflake.com/LIMITEDACCESS/snowflake-ml-model-registry for more details about the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5642606",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"MY_DATASET\"\n",
    "DATASET_VERSION = \"V1\"\n",
    "\n",
    "my_dataset = registry.log_artifact(\n",
    "    artifact=training_data,\n",
    "    name=DATASET_NAME,\n",
    "    version=DATASET_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd12070",
   "metadata": {},
   "source": [
    "Now you can log the model together with the registered artifact (which is a dataset here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MY_MODEL\"\n",
    "\n",
    "model_ref = registry.log_model(\n",
    "    model_name=model_name,\n",
    "    model_version=\"V2\",\n",
    "    model=rf,\n",
    "    tags={\"author\": \"my_rf_with_training_data\"},\n",
    "    artifacts=[my_dataset],\n",
    "    options={\"embed_local_ml_library\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf2743",
   "metadata": {},
   "source": [
    "### Step 2 : Restore model and predict with features\n",
    "\n",
    "We retrieve the training dataset from registry then construct dataframe of latest feature values. Then we restore the model from registry. At last, we can predict with latest feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.dataset.dataset import Dataset\n",
    "\n",
    "registered_dataset = registry.get_artifact(\n",
    "    DATASET_NAME, \n",
    "    DATASET_VERSION)\n",
    "test_df = spine_df.limit(3).select(\"WINE_ID\")\n",
    "\n",
    "enriched_df = fs.retrieve_feature_values(\n",
    "    test_df, registered_dataset.load_features())\n",
    "enriched_df = enriched_df.drop('WINE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = model_registry.ModelReference(\n",
    "    registry=registry, \n",
    "    model_name=model_name, \n",
    "    model_version=\"V2\"\n",
    ")\n",
    "restored_model = model_ref.load_model()\n",
    "restored_prediction = restored_model.predict(enriched_df.to_pandas())\n",
    "\n",
    "print(restored_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173da73",
   "metadata": {},
   "source": [
    "## Cleanup notebook\n",
    "Cleanup resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(f\"DROP DATABASE IF EXISTS {FS_DEMO_DB}\").collect()\n",
    "session.sql(f\"DROP DATABASE IF EXISTS {MR_DEMO_DB}\").collect()\n",
    "session.sql(f\"DROP WAREHOUSE IF EXISTS {FS_DEMO_WH}\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
